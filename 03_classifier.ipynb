{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Classifier for the breast cancer patients based on PAM50 subtypes\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "import scikit_posthocs as sp\n",
        "import shap\n",
        "from scipy.cluster import hierarchy\n",
        "from scipy.spatial.distance import squareform\n",
        "from scipy.stats import friedmanchisquare, spearmanr\n",
        "from sklearn.ensemble import (AdaBoostClassifier,\n",
        "                              HistGradientBoostingClassifier,\n",
        "                              RandomForestClassifier)\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (accuracy_score, classification_report, f1_score,\n",
        "                             precision_score, recall_score, roc_auc_score,\n",
        "                             silhouette_score)\n",
        "from sklearn.model_selection import (GridSearchCV, RepeatedKFold,\n",
        "                                     cross_val_score, train_test_split)\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def save_fig(fig_, savepath):\n",
        "    fig_.update_layout(dragmode='pan', margin=dict(l=0, r=0, t=30, b=30))\n",
        "    fig_.write_html(savepath, config={'scrollZoom': True, 'displaylogo': False})\n",
        "\n",
        "\n",
        "pio.templates.default = 'simple_white'\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_full = pd.read_csv('data/processed/filtered_dataset.csv', index_col=0)\n",
        "metadata_full = pd.read_csv('data/processed/metadata.csv', index_col=0)\n",
        "\n",
        "metadata = metadata_full.dropna(subset='PAM50').reset_index(drop=True)\n",
        "dataset = dataset_full.loc[:, metadata['submitter_id.samples']]\n",
        "\n",
        "degs_subset = pd.read_csv('data/processed/degs_subset.csv', index_col=0)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All genes\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.T\n",
        "y = metadata['PAM50']\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train test and validation sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers_all = {\n",
        "    'KNN': make_pipeline(StandardScaler(), KNeighborsClassifier()),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Logistic Regression': make_pipeline(StandardScaler(), LogisticRegression(\n",
        "        max_iter=10000, random_state=42)),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(algorithm='SAMME', random_state=42),\n",
        "    'SVM': make_pipeline(StandardScaler(), SVC(probability=True, random_state=42)),\n",
        "    'Gradient Boosting': HistGradientBoostingClassifier(random_state=42),\n",
        "    'Neural Network': make_pipeline(StandardScaler(), MLPClassifier(\n",
        "        hidden_layer_sizes=(200, 200, 100),\n",
        "        max_iter=1000,\n",
        "        early_stopping=True,\n",
        "        random_state=42))\n",
        "}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train and evaluate classifiers\n",
        "results = {}\n",
        "for name, clf in (pbar := tqdm(classifiers_all.items())):\n",
        "    pbar.set_description(f'fitting {name}')\n",
        "    clf.fit(X_train, y_train)\n",
        "    pbar.set_description(f'predicting with {name}')\n",
        "    y_pred = clf.predict(X_val)\n",
        "    pbar.set_description(f'evaluating {name}')\n",
        "    y_proba = (clf.predict_proba(X_val)\n",
        "               if hasattr(clf, \"predict_proba\") else clf.decision_function(X_val))\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy_score(y_val, y_pred),\n",
        "        'Precision': precision_score(y_val, y_pred, average='weighted', zero_division=0),\n",
        "        'Recall': recall_score(y_val, y_pred, average='weighted'),\n",
        "        'F1-score': f1_score(y_val, y_pred, average='weighted'),\n",
        "        'ROC AUC': roc_auc_score(y_val, y_proba, average='weighted', multi_class='ovo')\n",
        "    }\n",
        "\n",
        "results_all_genes = pd.DataFrame(results).T\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Results using all genes:\")\n",
        "results_all_genes.sort_values('F1-score', ascending=False)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = Path('results/classifiers_evaluation')\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "results_all_genes.sort_values('F1-score', ascending=False).to_csv(output_dir / 'all_genes.csv')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Degs subset\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = degs_subset.T\n",
        "y = metadata['PAM50']\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train test and validation sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers_degs = {\n",
        "    'KNN': make_pipeline(StandardScaler(), KNeighborsClassifier()),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Logistic Regression': make_pipeline(StandardScaler(), LogisticRegression(\n",
        "        max_iter=10000, random_state=42)),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(algorithm='SAMME', random_state=42),\n",
        "    'SVM': make_pipeline(StandardScaler(), SVC(probability=True, random_state=42)),\n",
        "    'Gradient Boosting': HistGradientBoostingClassifier(random_state=42),\n",
        "    'Neural Network': make_pipeline(StandardScaler(), MLPClassifier(\n",
        "        hidden_layer_sizes=(200, 200, 100),\n",
        "        max_iter=1000,\n",
        "        early_stopping=True,\n",
        "        random_state=42))\n",
        "}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train and evaluate classifiers\n",
        "results = {}\n",
        "for name, clf in (pbar := tqdm(classifiers_degs.items())):\n",
        "    pbar.set_description(f'fitting {name}')\n",
        "    clf.fit(X_train, y_train)\n",
        "    pbar.set_description(f'predicting with {name}')\n",
        "    y_pred = clf.predict(X_val)\n",
        "    pbar.set_description(f'evaluating {name}')\n",
        "    y_proba = (clf.predict_proba(X_val)\n",
        "               if hasattr(clf, \"predict_proba\") else clf.decision_function(X_val))\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy_score(y_val, y_pred),\n",
        "        'Precision': precision_score(y_val, y_pred, average='weighted', zero_division=0),\n",
        "        'Recall': recall_score(y_val, y_pred, average='weighted'),\n",
        "        'F1-score': f1_score(y_val, y_pred, average='weighted'),\n",
        "        'ROC AUC': roc_auc_score(y_val, y_proba, average='weighted', multi_class='ovo')\n",
        "    }\n",
        "\n",
        "\n",
        "results_degs = pd.DataFrame(results).T\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Results using DEGs:\")\n",
        "results_degs.sort_values('F1-score', ascending=False)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_degs.sort_values('F1-score', ascending=False).to_csv(output_dir / 'degs.csv')\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML algorithms gave almost the same evaluation scores on all genes and on DEGs only,\n",
        "while training only on DEGs is significantly faster. Now let's tune the hyperparameters of\n",
        "top 3 algorithms (by F1-score): Gradient Boosting, Random Forest, SVM.\n",
        "\n",
        "Choice of F1-score over ROC AUC is determined by importance of good precision and recall,\n",
        "while diagnosing breast cancer subtype (high cost of false positives and false negatives),\n",
        "and because of imbalance in classes.\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning hyperparameters\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_space_gb = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_iter': [100, 200, 300],\n",
        "    'max_leaf_nodes': [21, 31, 41]\n",
        "}\n",
        "\n",
        "grid_search_gb = GridSearchCV(\n",
        "    classifiers_degs['Gradient Boosting'],\n",
        "    param_space_gb,\n",
        "    n_jobs=-1,\n",
        "    scoring='f1_weighted',\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "grid_search_gb.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters found for Gradient Boosting: \", grid_search_gb.best_params_)\n",
        "print(\"Best F1-score for Gradient Boosting: \", grid_search_gb.best_score_)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output:\n",
        "\n",
        "`{'learning_rate': 0.1, 'max_iter': 200, 'max_leaf_nodes': 31}`\n",
        "\n",
        "`0.8012793592379689`\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_space_svm = {\n",
        "    'svc__C': [0.1, 1, 10],\n",
        "    'svc__gamma': ['scale', 'auto'],\n",
        "    'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "}\n",
        "\n",
        "grid_search_svm = GridSearchCV(\n",
        "    classifiers_degs['SVM'],\n",
        "    param_space_svm,\n",
        "    n_jobs=-1,\n",
        "    scoring='f1_weighted',\n",
        "    verbose=1,\n",
        "    cv=5,\n",
        ")\n",
        "\n",
        "grid_search_svm.fit(X_train, y_train)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best parameters found for SVM: \", grid_search_svm.best_params_)\n",
        "print(\"Best F1-score for SVM: \", grid_search_svm.best_score_)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output:\n",
        "\n",
        "`{'svc__C': 1, 'svc__gamma': 'scale', 'svc__kernel': 'linear'}`\n",
        "\n",
        "`0.8072037282506166`\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_space_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [None, 10, 20, 30]\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(\n",
        "    classifiers_degs['Random Forest'],\n",
        "    param_space_rf,\n",
        "    n_jobs=-1,\n",
        "    scoring='f1_weighted',\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best parameters found for Random Forest: \", grid_search_rf.best_params_)\n",
        "print(\"Best F1-score for Random Forest: \", grid_search_rf.best_score_)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output:\n",
        "\n",
        "`{'max_depth': None, 'max_features': None, 'n_estimators': 300}`\n",
        "\n",
        "`0.8172762597861276`, `0.814` for `n_estimators=100`\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With both metrics (f1-weighted and f1-macro) Random Forest outperforms SVM and Gradient Boosting.\n",
        "\n",
        "Let's check, does n_estimators=100 vs 300 gives statistical difference in RF,\n",
        "and compare it with GB and SVM (with optimized parameters).\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = {\n",
        "    'rf1': RandomForestClassifier(\n",
        "        **{'max_depth': None, 'max_features': None,\n",
        "            'n_estimators': 100}),\n",
        "    'rf2': RandomForestClassifier(\n",
        "        **{'max_depth': None, 'max_features': None,\n",
        "            'n_estimators': 300}),\n",
        "    'gb': HistGradientBoostingClassifier(\n",
        "        **{'learning_rate': 0.1, 'max_iter': 200,\n",
        "            'max_leaf_nodes': 31}),\n",
        "    'svm': make_pipeline(StandardScaler(), SVC(\n",
        "        **{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}))\n",
        "}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rkf = RepeatedKFold(n_splits=5, n_repeats=5,\n",
        "                    random_state=42)\n",
        "\n",
        "scores = {}\n",
        "for name, clf in (pbar := tqdm(classifiers.items())):\n",
        "    pbar.set_description(name)\n",
        "    scores[name] = cross_val_score(\n",
        "        clf, X_train, y_train, cv=rkf,\n",
        "        n_jobs=-1, verbose=2,\n",
        "        scoring='f1_weighted')\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_melted = pd.DataFrame(scores).melt(var_name='Classifier', value_name='F1-score')\n",
        "df_melted.to_csv('results/classifiers_evaluation/tuning_results.csv', index=False)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_np = np.vstack((scores['rf1'], scores['rf2'], scores['gb'], scores['svm'])).T\n",
        "\n",
        "friedman_stat, friedman_p = friedmanchisquare(\n",
        "    scores['rf1'], scores['rf2'], scores['gb'], scores['svm'])\n",
        "print(f'Friedman test statistic={friedman_stat}, p-value={friedman_p}')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if friedman_p < 0.05:\n",
        "    nemenyi_result = sp.posthoc_nemenyi_friedman(scores_np)\n",
        "    print(\"Nemenyi test results:\\n\", nemenyi_result)\n",
        "else:\n",
        "    print(\"No significant differences found among models using Friedman test.\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('rf1: ', scores['rf1'].mean(), scores['rf1'].std())\n",
        "print('rf2: ', scores['rf2'].mean(), scores['rf2'].std())\n",
        "print('gb: ', scores['gb'].mean(), scores['gb'].std())\n",
        "print('svm: ', scores['svm'].mean(), scores['svm'].std())\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_melted = pd.read_csv('results/classifiers_evaluation/tuning_results.csv')\n",
        "\n",
        "\n",
        "fig = px.violin(df_melted, x='Classifier', y='F1-score',\n",
        "                color='Classifier',\n",
        "                box=True, points='all')\n",
        "fig.update_layout(showlegend=False)\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=['rf1', 'gb'],\n",
        "    y=[0.92, 0.92],\n",
        "    mode=\"lines\",\n",
        "    line=dict(color=\"black\", width=1),\n",
        "    showlegend=False\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=['rf1', 'rf1'],\n",
        "    y=[0.92, 0.91],\n",
        "    mode=\"lines\",\n",
        "    line=dict(color=\"black\", width=1),\n",
        "    showlegend=False\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=['gb', 'gb'],\n",
        "    y=[0.92, 0.91],\n",
        "    mode=\"lines\",\n",
        "    line=dict(color=\"black\", width=1),\n",
        "    showlegend=False\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=['rf2', 'rf2'],\n",
        "    y=[0.92, 0.93],\n",
        "    mode=\"lines\",\n",
        "    line=dict(color=\"black\", width=1),\n",
        "    showlegend=False\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=['rf2', 'svm'],\n",
        "    y=[0.93, 0.93],\n",
        "    mode=\"lines\",\n",
        "    line=dict(color=\"black\", width=1),\n",
        "    showlegend=False\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=['svm', 'svm'],\n",
        "    y=[0.93, 0.91],\n",
        "    mode=\"lines\",\n",
        "    line=dict(color=\"black\", width=1),\n",
        "    showlegend=False\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=['gb'],\n",
        "    y=[0.93],\n",
        "    mode=\"text\",\n",
        "    text=[\"*\"],\n",
        "    textposition=\"top center\",\n",
        "    textfont=dict(size=20),\n",
        "    showlegend=False\n",
        "))\n",
        "\n",
        "fig.show()\n",
        "save_fig(fig, 'results/figures/classifiers_comparison.html')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results:\n",
        "\n",
        "mean and std:\n",
        "\n",
        "`rf1:  0.814729169017811 0.024106169329451487\n",
        "rf2:  0.8167264811361582 0.024605705361264024\n",
        "gb:  0.812763429534384 0.02430571116017395\n",
        "svm:  0.7928911647913511 0.030927744325978224`\n",
        "\n",
        "Nemenyi test results:\n",
        "\n",
        "`           0         1         2         3\n",
        "0  1.000000  0.608787  0.900000  0.049306\n",
        "1  0.608787  1.000000  0.639529  0.001000\n",
        "2  0.900000  0.639529  1.000000  0.042567\n",
        "3  0.049306  0.001000  0.042567  1.000000`\n",
        "\n",
        "So, rf1, rf2, and gb don't have significant differences,\n",
        "and they all perform better than SVM.\n",
        "\n",
        "Therefore, we'll choose rf1, as this model is less computationally expensive\n",
        "than rf2 and gb.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf1 = classifiers['rf1']\n",
        "\n",
        "X_train_final = pd.concat([X_train, X_val])\n",
        "y_train_final = pd.concat([y_train, y_val])\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf1.fit(X_train_final, y_train_final)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = rf1.predict(X_test)\n",
        "y_test_proba = rf1.predict_proba(X_test)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_precision = precision_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
        "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
        "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "test_roc_auc = roc_auc_score(y_test, y_test_proba, average='weighted', multi_class='ovo')\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1-score: {test_f1:.4f}\")\n",
        "print(f\"Test ROC AUC: {test_roc_auc:.4f}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_test_pred))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature importance evaluation\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on mean decrease in impurity\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature importances for all dataset\n",
        "importance_df_all = pd.DataFrame({\n",
        "    'gene': X_train_final.columns,\n",
        "    'All_mean': rf1.feature_importances_,\n",
        "    'All_std': np.std([rf1.feature_importances_ for tree in rf1.estimators_], axis=0),\n",
        "}\n",
        ").set_index('gene')\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# by subtypes\n",
        "rf = OneVsRestClassifier(RandomForestClassifier(\n",
        "    **{'max_depth': None, 'max_features': None, 'n_estimators': 100}))\n",
        "rf.fit(X_train_final, y_train_final)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = rf.classes_\n",
        "\n",
        "importance_dict = {}\n",
        "for idx, class_label in enumerate(classes):\n",
        "    class_importance = rf.estimators_[idx].feature_importances_\n",
        "    importance_dict[f'{class_label}_mean'] = class_importance\n",
        "    importance_dict[f'{class_label}_std'] = np.std([\n",
        "        rf.estimators_[idx].feature_importances_ for tree\n",
        "        in rf.estimators_[idx].estimators_])\n",
        "\n",
        "importance_df = pd.DataFrame(importance_dict, index=X_train_final.columns)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df = importance_df.join(importance_df_all)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = Path('results/feature_importance')\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "importance_df.to_csv(output_dir / 'feature_importance_rf_impurity.csv')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get most important genes for each subtype\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df = pd.read_csv('results/feature_importance/feature_importance_rf_impurity.csv',\n",
        "                            index_col=0)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes = pd.DataFrame(\n",
        "    {subtype.split('_', 1)[0]:\n",
        "     importance_df.sort_values(\n",
        "        by=subtype, ascending=False).index.tolist()\n",
        "     for subtype in importance_df.columns if not subtype.endswith('_std')})\n",
        "important_genes = important_genes[['All', 'LumA', 'LumB', 'Her2', 'Basal', 'Normal']]\n",
        "important_genes.to_csv('results/feature_importance/important_genes_rf_impurity.csv', index=False)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes.head(10)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on feature permutation\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's remove multicollinear features and use only central genes from clusters,\n",
        "as multicollinear features might hide some important feature during permutation.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = spearmanr(X).correlation\n",
        "corr = (corr + corr.T) / 2\n",
        "np.fill_diagonal(corr, 1)\n",
        "\n",
        "distance_matrix = 1 - np.abs(corr)\n",
        "dist_linkage = hierarchy.ward(squareform(distance_matrix))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.linspace(0.1, 2.0, 20)\n",
        "silhouette_scores = []\n",
        "\n",
        "for t in thresholds:\n",
        "    cluster_labels = hierarchy.fcluster(dist_linkage, t=t, criterion='distance')\n",
        "    score = silhouette_score(distance_matrix, cluster_labels, metric='precomputed')\n",
        "    silhouette_scores.append(score)\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=thresholds,\n",
        "    y=silhouette_scores,\n",
        "    mode='lines+markers',\n",
        "    name='Silhouette Score'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Threshold',\n",
        "    yaxis_title='Silhouette Score'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimal_threshold = thresholds[np.argmax(silhouette_scores)]\n",
        "print('Optimal threshold:', optimal_threshold)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_labels = hierarchy.fcluster(dist_linkage, optimal_threshold, criterion='distance')\n",
        "genes_clusters = pd.DataFrame({'Gene': X.columns, 'Cluster': cluster_labels})\n",
        "\n",
        "\n",
        "def select_representative_gene(cluster_genes):\n",
        "    cluster_data = X[cluster_genes]\n",
        "    mean_correlation = cluster_data.corr().mean().sort_values(ascending=False)\n",
        "    return mean_correlation.index[0]\n",
        "\n",
        "\n",
        "representative_genes = genes_clusters.groupby(\n",
        "    'Cluster')['Gene'].apply(select_representative_gene).tolist()\n",
        "\n",
        "X_train_sel = X_train_final[representative_genes]\n",
        "X_test_sel = X_test[representative_genes]\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_sel = RandomForestClassifier(\n",
        "    **{'max_depth': None, 'max_features': None,\n",
        "        'n_estimators': 100})\n",
        "clf_sel.fit(X_train_sel, y_train_final)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_sel = clf_sel.predict(X_test_sel)\n",
        "print(classification_report(y_test, y_test_pred_sel))\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform feature permutation\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for all subtypes combined:\n",
        "result = permutation_importance(clf_sel, X_train_sel, y_train_final,\n",
        "                                scoring='f1_weighted', random_state=42, n_jobs=-1)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances_all = pd.DataFrame({\n",
        "    'gene': X_train_sel.columns,\n",
        "    'All_mean': result.importances_mean,\n",
        "    'All_std': result.importances_std\n",
        "}).set_index('gene').sort_values(by='All_mean', ascending=False)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for each subtype:\n",
        "y_pred = clf_sel.predict(X_train_sel)\n",
        "\n",
        "feature_importances = {}\n",
        "\n",
        "for subtype in (pbar := tqdm(y.unique())):\n",
        "    pbar.set_description(subtype)\n",
        "    if y_train_final[y_pred == subtype].shape != (0,):\n",
        "        result = permutation_importance(\n",
        "            clf_sel,\n",
        "            X_train_sel[y_pred == subtype], y_pred[y_pred == subtype],\n",
        "            scoring='f1_weighted', random_state=42, n_jobs=-1)\n",
        "        feature_importances[subtype] = pd.DataFrame({\n",
        "            'gene': X_train_sel.columns,\n",
        "            f'{subtype}_mean': result.importances_mean,\n",
        "            f'{subtype}_std': result.importances_std\n",
        "        }).set_index('gene').sort_values(by=f'{subtype}_mean', ascending=False)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance_permutation = pd.concat(list(feature_importances.values()) + [feature_importances_all],\n",
        "                                   axis=1)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance_permutation.to_csv(output_dir / 'feature_importance_rf_permutation.csv')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes_permutation = pd.DataFrame({subtype.split('_', 1)[0]:\n",
        "                                            importance_permutation.sort_values(\n",
        "    by=subtype, ascending=False).index.tolist()\n",
        "    for subtype in importance_permutation.columns if not subtype.endswith('_std')})\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes_permutation = important_genes_permutation[[\n",
        "    'All', 'LumA', 'LumB', 'Her2', 'Basal', 'Normal']]\n",
        "important_genes_permutation.to_csv(\n",
        "    'results/feature_importance/important_genes_rf_permutation.csv', index=False)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes_permutation.head(10)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes_impurity = pd.read_csv(\n",
        "    'results/feature_importance/important_genes_rf_impurity.csv')\n",
        "important_genes_impurity.head(10)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform feature permutation without removing correlated features\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for all subtypes combined:\n",
        "result = permutation_importance(rf1, X_train_final, y_train_final,\n",
        "                                scoring='f1_weighted', random_state=42, n_jobs=-1)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances_all = pd.DataFrame({\n",
        "    'gene': X_train_final.columns,\n",
        "    'All_mean': result.importances_mean,\n",
        "    'All_std': result.importances_std\n",
        "}).set_index('gene').sort_values(by='All_mean', ascending=False)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for each subtype:\n",
        "y_pred = rf1.predict(X_train_final)\n",
        "\n",
        "feature_importances = {}\n",
        "\n",
        "for subtype in (pbar := tqdm(y.unique())):\n",
        "    pbar.set_description(subtype)\n",
        "    if y_train_final[y_pred == subtype].shape != (0,):\n",
        "        result = permutation_importance(\n",
        "            rf1,\n",
        "            X_train_final[y_pred == subtype], y_pred[y_pred == subtype],\n",
        "            scoring='f1_weighted', random_state=42, n_jobs=-1)\n",
        "        feature_importances[subtype] = pd.DataFrame({\n",
        "            'gene': X_train_final.columns,\n",
        "            f'{subtype}_mean': result.importances_mean,\n",
        "            f'{subtype}_std': result.importances_std\n",
        "        }).set_index('gene').sort_values(by=f'{subtype}_mean', ascending=False)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance_permutation = pd.concat(list(feature_importances.values()) + [feature_importances_all],\n",
        "                                   axis=1)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = Path('results/feature_importance/')\n",
        "importance_permutation.to_csv(output_dir / 'feature_importance_rf_permutation_all.csv')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes_permutation = pd.DataFrame({subtype.split('_', 1)[0]:\n",
        "                                            importance_permutation.sort_values(\n",
        "    by=subtype, ascending=False).index.tolist()\n",
        "    for subtype in importance_permutation.columns if not subtype.endswith('_std')})\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes_permutation = important_genes_permutation[[\n",
        "    'All', 'LumA', 'LumB', 'Her2', 'Basal', 'Normal']]\n",
        "important_genes_permutation.to_csv(\n",
        "    'results/feature_importance/important_genes_rf_permutation_all.csv', index=False)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes_permutation.head(10)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = rf1.classes_\n",
        "\n",
        "explainer = shap.TreeExplainer(rf1)\n",
        "shap_values = explainer.shap_values(X_train_final)\n",
        "\n",
        "importance_shap_all = pd.DataFrame({\n",
        "    'gene': X_train_final.columns,\n",
        "    'All_mean': np.abs(shap_values).mean(axis=(0, 2)),\n",
        "    'All_std': np.abs(shap_values).std(axis=(0, 2))\n",
        "}).set_index('gene').sort_values(by='All_mean', ascending=False)\n",
        "\n",
        "feature_importances = {}\n",
        "for i, class_name in enumerate(class_names):\n",
        "    feature_importances[class_name] = pd.DataFrame({\n",
        "        'gene': X_train_final.columns,\n",
        "        f'{class_name}_mean': np.abs(shap_values[:, :, i]).mean(axis=0),\n",
        "        f'{class_name}_std': np.abs(shap_values[:, :, i]).std(axis=0)\n",
        "    }).set_index('gene').sort_values(by=f'{class_name}_mean', ascending=False)\n",
        "\n",
        "importance_shap = pd.concat(list(feature_importances.values()) + [importance_shap_all], axis=1)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance_shap.to_csv(output_dir / 'feature_importance_rf_shap.csv')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes_shap = pd.DataFrame({subtype.split('_', 1)[0]:\n",
        "                                     importance_shap.sort_values(\n",
        "    by=subtype, ascending=False).index.tolist()\n",
        "    for subtype in importance_shap.columns if not subtype.endswith('_std')})\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes_shap = important_genes_shap[[\n",
        "    'All', 'LumA', 'LumB', 'Her2', 'Basal', 'Normal']]\n",
        "important_genes_shap.to_csv(\n",
        "    'results/feature_importance/important_genes_rf_shap.csv', index=False)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_genes_shap.head(10)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot most important features from all methods\n",
        "method_to_df = {\n",
        "    'Impurity': pd.read_csv(\n",
        "        'results/feature_importance/feature_importance_rf_impurity.csv', index_col=0),\n",
        "    'Permutation': pd.read_csv(\n",
        "        'results/feature_importance/feature_importance_rf_permutation.csv', index_col=0),\n",
        "    'SHAP': pd.read_csv(\n",
        "        'results/feature_importance/feature_importance_rf_shap.csv', index_col=0)\n",
        "}\n",
        "\n",
        "method_to_axis_title = {\n",
        "    'Impurity': 'Mean decrease in impurity',\n",
        "    'Permutation': 'Mean F1-score decrease',\n",
        "    'SHAP': 'SHAP value'\n",
        "}\n",
        "\n",
        "subtype_to_common_genes = {\n",
        "    'All': [\n",
        "        'MLPH',\n",
        "        'FOXA1',\n",
        "        'ESR1',\n",
        "        'KRT14',\n",
        "        'TPX2',\n",
        "        'KRT5',\n",
        "        'SGOL1',\n",
        "        'LINC00504',\n",
        "        'NEIL3',\n",
        "    ],\n",
        "    'LumA': [\n",
        "        'TPX2',\n",
        "        'KRT14',\n",
        "        'SGOL1',\n",
        "        'KRT5',\n",
        "        'ESR1',\n",
        "        'CENPA',\n",
        "    ],\n",
        "    'LumB': [\n",
        "        'ESR1',\n",
        "        'TPX2',\n",
        "        'KRT14',\n",
        "        'MLPH',\n",
        "        'SGOL1',\n",
        "        'KRT5',\n",
        "        'NEIL3',\n",
        "    ],\n",
        "    'Her2': ['ESR1'],\n",
        "    'Basal': [\n",
        "        'MLPH',\n",
        "        'FOXA1',\n",
        "        'ESR1',\n",
        "        'TTC6',\n",
        "        'HJURP',\n",
        "    ],\n",
        "    'Normal': [\n",
        "        'TPX2',\n",
        "        'ESR1',\n",
        "        'KIF20A',\n",
        "        'KRT14',\n",
        "    ]\n",
        "}\n",
        "\n",
        "for c, (method, imp_df) in enumerate(method_to_df.items()):\n",
        "    for subtype, common_genes in subtype_to_common_genes.items():\n",
        "\n",
        "        plot_df = imp_df.sort_values(by=f'{subtype}_mean', ascending=False).head(10)[\n",
        "            [f'{subtype}_mean', f'{subtype}_std']]\n",
        "\n",
        "        # calculate standard error instead of std:\n",
        "        if method == 'Impurity':\n",
        "            plot_df[f'{subtype}_std'] = plot_df[f'{subtype}_std'] / np.sqrt(100)  # n_estimators\n",
        "        elif method == 'Permutation':\n",
        "            plot_df[f'{subtype}_std'] = plot_df[f'{subtype}_std'] / np.sqrt(5)  # n_repeats\n",
        "        else:\n",
        "            if subtype == 'All':\n",
        "                plot_df[f'{subtype}_std'] = (plot_df[f'{subtype}_std']  # n subtypes * n samples\n",
        "                                             / np.sqrt(5 * X_train_final.shape[0]))\n",
        "            else:\n",
        "                plot_df[f'{subtype}_std'] = (plot_df[f'{subtype}_std']  # n samples\n",
        "                                             / np.sqrt(X_train_final.shape[0]))\n",
        "\n",
        "        fig = px.bar(\n",
        "            plot_df.reset_index(),\n",
        "            x='gene',\n",
        "            y=f'{subtype}_mean',\n",
        "            error_y=f'{subtype}_std',\n",
        "            title=method,\n",
        "            labels={'gene': '', f'{subtype}_mean': method_to_axis_title[method]},\n",
        "            color='gene',\n",
        "            color_discrete_map={gene: px.colors.qualitative.D3[c] for gene in plot_df.index},\n",
        "            text=plot_df.index.map(lambda x: f'<b>{x}</b>' if x in common_genes else x)\n",
        "        )\n",
        "        fig.update_layout(\n",
        "            showlegend=False,\n",
        "            yaxis_range=[0, 1.1 * (plot_df[f'{subtype}_mean'].max()\n",
        "                                   + plot_df[f'{subtype}_std'].max())])\n",
        "        fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "        fig.update_xaxes(showticklabels=False, ticks='')\n",
        "        save_fig(fig, f'results/figures/{method}_{subtype}.html'.lower())\n",
        "        fig.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}